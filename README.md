# Web-Scraping-using-Scrapy


### After cloning this project, please follow the steps
``` bash
# For Postgres installation please follow this document:
https://www.digitalocean.com/community/tutorials/how-to-install-postgresql-on-ubuntu-20-04-quickstart
# After installing Postgres, please read the following documentation for installing pgadmin4:
https://kodemonk.dev/blog/installing-postgresql-on-ubuntu-20-04
# After installing pgadmin4, please create the database which name is  "store".

# install Scrapy
pip3 install scrapy
#install psycopg2 or psycopg2-binary
pip3 install psycopg2
pip3 install psycopg2-binary

# File directory:  \myproject\myproject\spiders\scrapy.py
cd myproject
cd myproject
cd spiders

# Run project: 
scrapy crawl quotes
```

### Using Tools and Libraries
1. pgAdmin 4
2. PyCharm
3. Scrapy
4. psycopg2
5. Json

### Project details
This project is crawling the data from website , then those data store into Postgres database.
##### Screenshoot
![100](https://user-images.githubusercontent.com/69507020/148771618-6904f71f-be80-46af-b458-9767d7f33cba.png)


